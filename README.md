# ğŸš€ BigData Analytics Dashboard with .NET 9 & Dapper

<div align="center">

![.NET 9](https://img.shields.io/badge/.NET-9.0-512BD4?style=for-the-badge&logo=dotnet&logoColor=white)
![Dapper](https://img.shields.io/badge/ORM-Dapper-EA2027?style=for-the-badge)
![MSSQL](https://img.shields.io/badge/Database-MSSQL-A4B0BE?style=for-the-badge&logo=microsoft-sql-server&logoColor=black)
![Python](https://img.shields.io/badge/Data_Gen-Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Big Data](https://img.shields.io/badge/Data-1.5M%20Rows-1B1464?style=for-the-badge)

<br />

**1.5 Milyon satÄ±rlÄ±k devasa bir e-ticaret veri setini analiz eden, yÃ¶neten ve gÃ¶rselleÅŸtiren yÃ¼ksek performanslÄ± Dashboard uygulamasÄ±.**

</div>

---

## ğŸ“– Proje HakkÄ±nda

Bu proje, gerÃ§ek hayat senaryolarÄ±na (Business Logic) uygun olarak **Python** ile simÃ¼le edilmiÅŸ, **MSSQL** veritabanÄ±na aktarÄ±lmÄ±ÅŸ ve **.NET 9.0 + Dapper** mimarisi kullanÄ±larak milisaniyeler iÃ§inde sorgulanmÄ±ÅŸ bir Big Data Ã§Ã¶zÃ¼mÃ¼dÃ¼r.

### ğŸ¯ Temel Ã–zellikler

| Ã–zellik | AÃ§Ä±klama |
| :--- | :--- |
| **âš¡ YÃ¼ksek Performans** | Klasik EF Core yerine **Dapper mikro-ORM** kullanÄ±larak maksimum sorgu hÄ±zÄ± ve minimum bellek kullanÄ±mÄ±. |
| **ğŸ“Š Ä°leri DÃ¼zey GÃ¶rselleÅŸtirme** | Veri akÄ±ÅŸÄ±, satÄ±ÅŸ analizleri ve mÃ¼ÅŸteri performanslarÄ±nÄ±n **ApexCharts/Chart.js** ile dinamik sunumu. |
| **ğŸ¤– AI Destekli Veri** | Google Colab Ã¼zerinde Ã§alÄ±ÅŸan Ã¶zel Python scripti ile Ã¼retilmiÅŸ **1.5 Milyon** satÄ±rlÄ±k tutarlÄ± ve iliÅŸkisel veri seti. |
| **ğŸ“¦ ModÃ¼ler Mimari** | **.NET 9.0 MVC**, Repository Pattern ve SOLID prensiplerine uygun temiz kod yapÄ±sÄ±. |

---

## ğŸ“Š Ekran GÃ¶rÃ¼ntÃ¼leri

<table>
  <tr>
    <td align="center">
      <img src="https://via.placeholder.com/800x450?text=Dashboard+Genel+Bakis" alt="Dashboard" width="100%" />
      <br /><em>Dashboard Genel BakÄ±ÅŸ</em>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="https://via.placeholder.com/800x450?text=Veri+Analiz+Grafikleri" alt="Charts" width="100%" />
      <br /><em>DetaylÄ± Veri Analiz Grafikleri</em>
    </td>
  </tr>
</table>

---

## ğŸ’¡ Neden Dapper?

1.5 Milyon satÄ±rlÄ±k bir tabloda Entity Framework Core (EF Core) ile yapÄ±lan sorgular, Ã¶zellikle karmaÅŸÄ±k JOIN iÅŸlemlerinde, Aggregation (SUM, COUNT) sorgularÄ±nda ve "Read-Only" senaryolarda bellek yÃ¶netimi (Change Tracking) nedeniyle yavaÅŸ kalabilmektedir.

Bu projede **Dapper** kullanarak ÅŸunlarÄ± saÄŸladÄ±k:

> * âœ… **Raw SQL GÃ¼cÃ¼:** SQL sorgularÄ±nÄ± doÄŸrudan ve optimize edilmiÅŸ ÅŸekilde Ã§alÄ±ÅŸtÄ±rdÄ±k.
> * âœ… **DÃ¼ÅŸÃ¼k Maliyet:** Object-Relational Mapping (ORM) maliyetini minimuma indirdik.
> * âœ… **AnlÄ±k Raporlama:** BÃ¼yÃ¼k veri setlerinde dashboard performansÄ±nÄ± maksimize ettik.

---









## ğŸ› ï¸ Kurulum ve Veri Seti OluÅŸturma (AdÄ±m AdÄ±m)

Bu proje veritabanÄ± odaklÄ±dÄ±r. UygulamayÄ± ayaÄŸa kaldÄ±rmadan Ã¶nce aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ederek veri setini oluÅŸturmanÄ±z gerekmektedir.

### AdÄ±m 1: Veri Setinin OluÅŸturulmasÄ± (Python)

Veri seti rastgele "lorem ipsum" verilerinden deÄŸil, belirli kategori, marka ve fiyat kurallarÄ±na gÃ¶re oluÅŸturulmuÅŸtur.

AÅŸaÄŸÄ±daki Python kodunu **Google Colab** veya lokal Python ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rarak `.csv` dosyalarÄ±nÄ± Ã¼retin.
> **Not:** Bu script `Final_Products.csv` ve 15 parÃ§a halinde `Final_Orders_Part_X.csv` dosyalarÄ± Ã¼retecektir.

```python
import csv
import random
from datetime import datetime, timedelta
import time
# Google Colab kullanÄ±yorsanÄ±z bu satÄ±rÄ± aÃ§Ä±n:
# from google.colab import files

# --- KESÄ°N AYARLAR ---
PRODUCT_COUNT = 1000       # 1.000 Ã‡eÅŸit Kaliteli ÃœrÃ¼n
ORDER_PARTS = 15           # 15 Dosya
ORDERS_PER_PART = 100000   # Her dosyada 100.000 SipariÅŸ (Toplam 1.5 Milyon)
CUSTOMER_COUNT = 1000      # MÃ¼ÅŸteri ID: 1 ile 1000 arasÄ±

# --- KATEGORÄ° VE ÃœRÃœN KURALLARI ---
category_rules = {
    1: {"items": [("Apple", "MacBook Air M2", 35000, 50000), ("Samsung", "Galaxy S23", 40000, 60000)], "desc": "Teknoloji"},
    2: {"items": [("Mavi", "Black Pro Jeans", 800, 1500), ("Zara", "T-Shirt", 300, 800)], "desc": "Giyim"},
    3: {"items": [("Karaca", "Tencere Seti", 2000, 5000), ("IKEA", "KitaplÄ±k", 1500, 4000)], "desc": "Ev"},
    # ... (DiÄŸer kategoriler scriptin tamamÄ±nda mevcuttur)
    15: {"items": [("Omron", "Tansiyon Aleti", 800, 2000), ("Oral-B", "DiÅŸ FÄ±rÃ§asÄ±", 600, 1500)], "desc": "SaÄŸlÄ±k"}
}

statuses = ["Teslim Edildi", "Kargoda", "HazÄ±rlanÄ±yor", "Ä°ptal Edildi"]

def generate_perfect_data():
    print("ğŸ› ï¸ ADIM 1: ÃœrÃ¼nler (Products) oluÅŸturuluyor...")
    # ... (ÃœrÃ¼n oluÅŸturma mantÄ±ÄŸÄ±) ...
    # Tam kod 'DataGenerator.py' dosyasÄ±ndadÄ±r.

    print("ğŸš€ ADIM 2: SipariÅŸler (Orders) oluÅŸturuluyor...")
    # ... (SipariÅŸ oluÅŸturma mantÄ±ÄŸÄ± - 1.5 Milyon dÃ¶ngÃ¼) ...
            
    print(f"ğŸ“¦ Dosyalar oluÅŸturuldu.")

if __name__ == "__main__":
    generate_perfect_data()
